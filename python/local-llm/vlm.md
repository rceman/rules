# ðŸ‘€ Vision Model (VLM) Rules

## 1. Model Choice

| Model                       | Size | Comment                       |
|-----------------------------|------|-------------------------------|
| xtuner/llavaâ€‘llamaâ€‘3â€‘8b     | 8â€¯GB | good textâ€‘UI understanding    |
| moatâ€‘vlmâ€‘base               | 2â€¯GB | very fast, lower quality      |

## 2. Runtime

Use `llama-cpp-python[vision]` (vision patch).  
Batch multiple frames to improve throughput.

## 3. OCR fallback

If the VLM fails to read fine text, fallback to **pytesseract**.

* Preâ€‘process screenshot: grayscale & threshold.

## 4. Security

Mask sensitive data (password fields) before saving screenshots.
